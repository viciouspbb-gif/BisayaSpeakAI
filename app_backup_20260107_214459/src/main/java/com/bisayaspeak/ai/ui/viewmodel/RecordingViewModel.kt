package com.bisayaspeak.ai.ui.viewmodel

import android.app.Application
import android.media.MediaPlayer
import android.speech.tts.TextToSpeech
import androidx.lifecycle.AndroidViewModel
import androidx.lifecycle.viewModelScope
import com.bisayaspeak.ai.data.model.LearningLevel
import com.bisayaspeak.ai.data.model.PronunciationData
import com.bisayaspeak.ai.data.repository.PronunciationRepository
import com.bisayaspeak.ai.data.repository.UsageRepository
import com.bisayaspeak.ai.utils.WavRecorder
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import java.io.File
import java.io.IOException
import java.util.Locale

/**
 * éŒ²éŸ³ã¨è¨ºæ–­ã®ViewModel
 */
class RecordingViewModel(application: Application) : AndroidViewModel(application) {
    
    private val repository = PronunciationRepository()
    private val usageRepository = UsageRepository(application)
    
    private var wavRecorder: WavRecorder? = null
    private var mediaPlayer: MediaPlayer? = null
    private var audioFile: File? = null
    private var tts: TextToSpeech? = null
    private var currentLevel: LearningLevel = LearningLevel.BEGINNER
    
    private val _recordingState = MutableStateFlow<RecordingState>(RecordingState.Idle)
    val recordingState: StateFlow<RecordingState> = _recordingState.asStateFlow()
    
    private val _diagnosisState = MutableStateFlow<DiagnosisState>(DiagnosisState.Idle)
    val diagnosisState: StateFlow<DiagnosisState> = _diagnosisState.asStateFlow()
    
    private val _isPlaying = MutableStateFlow(false)
    val isPlaying: StateFlow<Boolean> = _isPlaying.asStateFlow()
    
    private val _isPlayingReference = MutableStateFlow(false)
    val isPlayingReference: StateFlow<Boolean> = _isPlayingReference.asStateFlow()

    // éŒ²éŸ³ä¸­ã®éŸ³é‡ãƒ¬ãƒ™ãƒ« (0.0ã€œ1.0)
    private val _volumeLevel = MutableStateFlow(0f)
    val volumeLevel: StateFlow<Float> = _volumeLevel.asStateFlow()
    
    private var referenceMediaPlayer: MediaPlayer? = null
    
    // ä½¿ç”¨å›æ•°ç®¡ç†
    val remainingCount = usageRepository.getRemainingCount()
    val canDiagnose = usageRepository.canDiagnose()
    val canWatchAd = usageRepository.canWatchAd()
    val adWatchCount = usageRepository.getAdWatchCount()
    
    /**
     * éŒ²éŸ³ã‚’é–‹å§‹
     */
    fun startRecording() {
        viewModelScope.launch {
            try {
                // æ‰‹æœ¬éŸ³å£°ãŒå†ç”Ÿä¸­ã®å ´åˆã¯åœæ­¢ã—ã¦å¾…æ©Ÿ
                if (_isPlayingReference.value) {
                    android.util.Log.d("RecordingViewModel", "æ‰‹æœ¬éŸ³å£°å†ç”Ÿä¸­ã®ãŸã‚åœæ­¢ã—ã¾ã™")
                    stopPlayingReference()
                    // éŸ³å£°ãŒå®Œå…¨ã«åœæ­¢ã™ã‚‹ã¾ã§å°‘ã—å¾…ã¤
                    kotlinx.coroutines.delay(300)
                }
                
                // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆWAVå½¢å¼ï¼‰
                audioFile = File.createTempFile(
                    "bisaya_recording_",
                    ".wav",
                    getApplication<Application>().cacheDir
                )
                
                wavRecorder = WavRecorder().apply {
                    // éŸ³é‡å¤‰åŒ–ã‚’UIã«å±Šã‘ã‚‹
                    setOnAmplitudeListener { level ->
                        _volumeLevel.value = level
                    }
                }
                wavRecorder?.startRecording(audioFile!!)
                
                _recordingState.value = RecordingState.Recording
            } catch (e: Exception) {
                _recordingState.value = RecordingState.Error(e.message ?: "éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼")
            }
        }
    }
    
    /**
     * éŒ²éŸ³ã‚’åœæ­¢
     */
    fun stopRecording() {
        try {
            wavRecorder?.stopRecording()
            wavRecorder = null
            _volumeLevel.value = 0f
            _recordingState.value = RecordingState.Completed(audioFile)
        } catch (e: Exception) {
            _recordingState.value = RecordingState.Error(e.message ?: "éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼")
        }
    }
    
    /**
     * ç™ºéŸ³ã‚’è¨ºæ–­
     */
    fun diagnosePronunciation(word: String, level: LearningLevel) {
        val file = audioFile ?: run {
            android.util.Log.e("RecordingViewModel", "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            _diagnosisState.value = DiagnosisState.Error("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆç„¡éŸ³éŒ²éŸ³ã®æ¤œå‡ºï¼‰
        val fileSize = file.length()
        android.util.Log.d("RecordingViewModel", "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $fileSize bytes")
        
        if (fileSize < 1000) { // 1KBæœªæº€ã¯ç„¡éŸ³ã¨åˆ¤æ–­
            android.util.Log.e("RecordingViewModel", "éŒ²éŸ³ãŒçŸ­ã™ãã‚‹ã‹ç„¡éŸ³ã§ã™")
            _diagnosisState.value = DiagnosisState.Error("éŒ²éŸ³ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\nã‚‚ã†ä¸€åº¦ã€ã¯ã£ãã‚Šã¨ç™ºéŸ³ã—ã¦ãã ã•ã„ã€‚")
            return
        }
        
        // MediaPlayerã§éŒ²éŸ³æ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
        try {
            val mp = MediaPlayer().apply {
                setDataSource(file.absolutePath)
                prepare()
            }
            val duration = mp.duration
            mp.release()
            
            android.util.Log.d("RecordingViewModel", "éŒ²éŸ³æ™‚é–“: ${duration}ms")
            
            if (duration < 300) { // 0.3ç§’æœªæº€ã¯çŸ­ã™ãã‚‹
                android.util.Log.e("RecordingViewModel", "éŒ²éŸ³ãŒçŸ­ã™ãã¾ã™")
                _diagnosisState.value = DiagnosisState.Error("éŒ²éŸ³ãŒçŸ­ã™ãã¾ã™ã€‚\nã‚‚ã†ä¸€åº¦ã€ã‚†ã£ãã‚Šã¨ç™ºéŸ³ã—ã¦ãã ã•ã„ã€‚")
                return
            }
        } catch (e: Exception) {
            android.util.Log.e("RecordingViewModel", "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: ${e.message}")
            _diagnosisState.value = DiagnosisState.Error("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãéŒ²éŸ³ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\nã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            return
        }
        
        viewModelScope.launch {
            android.util.Log.d("RecordingViewModel", "è¨ºæ–­é–‹å§‹: word=$word, level=$level, file=${file.absolutePath}")
            _diagnosisState.value = DiagnosisState.Loading
            
            val result = repository.checkPronunciation(file, word, level)
            
            _diagnosisState.value = if (result.isSuccess) {
                val response = result.getOrNull()!!
                android.util.Log.d("RecordingViewModel", "è¨ºæ–­æˆåŠŸ")
                android.util.Log.d("RecordingViewModel", "ã‚¹ã‚³ã‚¢: ${response.score}")
                android.util.Log.d("RecordingViewModel", "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ${response.feedback}")
                
                // ã‚¹ã‚³ã‚¢ãŒ0ã®å ´åˆã¯å‚ç…§éŸ³å£°ãŒãªã„
                if (response.score == 0) {
                    android.util.Log.w("RecordingViewModel", "è­¦å‘Š: ã‚¹ã‚³ã‚¢ãŒ0ã§ã™ã€‚ã‚µãƒ¼ãƒãƒ¼å´ã§å‚ç…§éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    android.util.Log.w("RecordingViewModel", "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ${response.feedback}")
                    
                    // å‚ç…§éŸ³å£°ãŒãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦æ‰±ã†
                    val context = getApplication<Application>()
                    DiagnosisState.Error("ã“ã®å˜èªã®å‚ç…§éŸ³å£°ãŒã¾ã æº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\nåˆ¥ã®å˜èªã§è©¦ã—ã¦ãã ã•ã„ã€‚")
                } else {
                    // PronunciationResponseã‚’PronunciationDataã«å¤‰æ›
                    val data = PronunciationData(
                        score = response.score,
                        feedback = response.feedback ?: "è¨ºæ–­çµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ",
                        detailedFeedback = response.detailedFeedback ?: emptyList(),
                        tips = response.tips ?: emptyList()
                    )
                    
                    // è¨ºæ–­æˆåŠŸæ™‚ã«å›æ•°ã‚’å¢—ã‚„ã™
                    usageRepository.incrementDiagnosisCount()
                    DiagnosisState.Success(data)
                }
            } else {
                val errorMessage = result.exceptionOrNull()?.message ?: "è¨ºæ–­ã‚¨ãƒ©ãƒ¼"
                android.util.Log.e("RecordingViewModel", "è¨ºæ–­å¤±æ•—: $errorMessage")
                
                // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã«å¤‰æ›
                val context = getApplication<Application>()
                val friendlyMessage = when {
                    errorMessage.contains("timeout", ignoreCase = true) -> 
                        context.getString(com.bisayaspeak.ai.R.string.error_server_starting)
                    errorMessage.contains("network", ignoreCase = true) || 
                    errorMessage.contains("connection", ignoreCase = true) -> 
                        context.getString(com.bisayaspeak.ai.R.string.error_network)
                    errorMessage.contains("500", ignoreCase = true) -> 
                        context.getString(com.bisayaspeak.ai.R.string.error_server_error)
                    else -> context.getString(com.bisayaspeak.ai.R.string.error_diagnosis)
                }
                
                DiagnosisState.Error(friendlyMessage)
            }
        }
    }
    
    /**
     * éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’å†ç”Ÿ
     */
    fun playRecording() {
        val file = audioFile ?: return
        
        try {
            stopPlaying() // æ—¢ã«å†ç”Ÿä¸­ãªã‚‰åœæ­¢
            
            mediaPlayer = MediaPlayer().apply {
                setDataSource(file.absolutePath)
                prepare()
                setOnCompletionListener {
                    _isPlaying.value = false
                }
                start()
            }
            _isPlaying.value = true
        } catch (e: Exception) {
            _isPlaying.value = false
        }
    }
    
    /**
     * å†ç”Ÿã‚’åœæ­¢
     */
    fun stopPlaying() {
        mediaPlayer?.apply {
            if (isPlaying) {
                stop()
            }
            release()
        }
        mediaPlayer = null
        _isPlaying.value = false
    }
    
    /**
     * ãŠæ‰‹æœ¬éŸ³å£°ã‚’å†ç”Ÿ
     */
    fun playReferenceAudio(word: String, level: LearningLevel = LearningLevel.BEGINNER) {
        currentLevel = level
        viewModelScope.launch {
            try {
                android.util.Log.d("RecordingViewModel", "ãŠæ‰‹æœ¬éŸ³å£°å†ç”Ÿé–‹å§‹: $word")
                stopPlayingReference() // æ—¢ã«å†ç”Ÿä¸­ãªã‚‰åœæ­¢
                
                // ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å‚ç…§éŸ³å£°ã‚’å–å¾—
                android.util.Log.d("RecordingViewModel", "ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰éŸ³å£°å–å¾—ä¸­...")
                val response = repository.getReferenceAudio(word)
                
                if (response.isSuccess) {
                    val audioData = response.getOrNull()
                    android.util.Log.d("RecordingViewModel", "éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: ${audioData?.size} bytes")
                    if (audioData != null && audioData.isNotEmpty()) {
                        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                        val tempFile = File.createTempFile(
                            "reference_",
                            ".mp3",
                            getApplication<Application>().cacheDir
                        )
                        tempFile.writeBytes(audioData)
                        android.util.Log.d("RecordingViewModel", "ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: ${tempFile.absolutePath}")
                        
                        // å†ç”Ÿ
                        referenceMediaPlayer = MediaPlayer().apply {
                            setDataSource(tempFile.absolutePath)
                            prepare()
                            setOnCompletionListener {
                                _isPlayingReference.value = false
                                tempFile.delete()
                            }
                            start()
                        }
                        _isPlayingReference.value = true
                        android.util.Log.d("RecordingViewModel", "å†ç”Ÿé–‹å§‹")
                    } else {
                        android.util.Log.e("RecordingViewModel", "éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç©º")
                    }
                } else {
                    android.util.Log.e("RecordingViewModel", "éŸ³å£°å–å¾—å¤±æ•—: ${response.exceptionOrNull()?.message}")
                    // ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã§ããªã„å ´åˆã¯TTSã§ä»£ç”¨
                    android.util.Log.d("RecordingViewModel", "TTSã§ä»£ç”¨å†ç”Ÿ")
                    playWithTTS(word, currentLevel)
                }
            } catch (e: Exception) {
                android.util.Log.e("RecordingViewModel", "ã‚¨ãƒ©ãƒ¼: ${e.message}", e)
                _isPlayingReference.value = false
            }
        }
    }
    
    /**
     * TTSã§éŸ³å£°ã‚’å†ç”Ÿï¼ˆãƒ¬ãƒ™ãƒ«åˆ¥ã®é€Ÿåº¦èª¿æ•´ï¼‰
     */
    private fun playWithTTS(text: String, level: LearningLevel = LearningLevel.BEGINNER) {
        val speechRate = when (level) {
            LearningLevel.BEGINNER -> 0.7f      // ğŸ• é…ã„
            LearningLevel.INTERMEDIATE -> 1.0f  // â± é€šå¸¸
            LearningLevel.ADVANCED -> 1.3f      // âš¡ é€Ÿã„
        }
        
        if (tts == null) {
            tts = TextToSpeech(getApplication()) { status ->
                if (status == TextToSpeech.SUCCESS) {
                    val result = tts?.setLanguage(Locale("fil", "PH"))
                    if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                        android.util.Log.e("RecordingViewModel", "TTSè¨€èªãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    } else {
                        tts?.setSpeechRate(speechRate)
                        tts?.speak(text, TextToSpeech.QUEUE_FLUSH, null, null)
                        _isPlayingReference.value = true
                    }
                }
            }
        } else {
            tts?.setSpeechRate(speechRate)
            tts?.speak(text, TextToSpeech.QUEUE_FLUSH, null, null)
            _isPlayingReference.value = true
        }
        
        // å†ç”Ÿçµ‚äº†å¾Œã«ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆç°¡æ˜“çš„ã«3ç§’å¾Œï¼‰
        viewModelScope.launch {
            kotlinx.coroutines.delay(3000)
            _isPlayingReference.value = false
        }
    }
    
    /**
     * ãŠæ‰‹æœ¬éŸ³å£°ã®å†ç”Ÿã‚’åœæ­¢
     */
    fun stopPlayingReference() {
        referenceMediaPlayer?.apply {
            if (isPlaying) {
                stop()
            }
            release()
        }
        referenceMediaPlayer = null
        tts?.stop()
        _isPlayingReference.value = false
    }
    
    /**
     * åºƒå‘Šè¦–è´å¾Œã«å›æ•°ã‚’å¾©æ´»
     */
    fun onAdWatched() {
        viewModelScope.launch {
            usageRepository.incrementAdWatchCount()
        }
    }
    
    /**
     * çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
     */
    fun reset() {
        stopPlaying()
        stopPlayingReference()
        _recordingState.value = RecordingState.Idle
        _diagnosisState.value = DiagnosisState.Idle
        _volumeLevel.value = 0f
        audioFile?.delete()
        audioFile = null
    }
    
    override fun onCleared() {
        super.onCleared()
        stopPlaying()
        stopPlayingReference()
        wavRecorder?.stopRecording()
        audioFile?.delete()
        tts?.shutdown()
        _volumeLevel.value = 0f
    }
}

/**
 * éŒ²éŸ³çŠ¶æ…‹
 */
sealed class RecordingState {
    object Idle : RecordingState()
    object Recording : RecordingState()
    data class Completed(val file: File?) : RecordingState()
    data class Error(val message: String) : RecordingState()
}

/**
 * è¨ºæ–­çŠ¶æ…‹
 */
sealed class DiagnosisState {
    object Idle : DiagnosisState()
    object Loading : DiagnosisState()
    data class Success(val result: PronunciationData) : DiagnosisState()
    data class Error(val message: String) : DiagnosisState()
}
